<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArchAI - Architectural Evaluation Assistant</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load Inter font -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Custom scrollbar */
        #chat-history::-webkit-scrollbar {
            width: 6px;
        }
        #chat-history::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 10px;
        }
        #chat-history::-webkit-scrollbar-thumb {
            background: #888;
            border-radius: 10px;
        }
        #chat-history::-webkit-scrollbar-thumb:hover {
            background: #555;
        }
        .dot-flashing {
            position: relative;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #4b5563;
            color: #4b5563;
            animation: dotFlashing 1s infinite linear alternate;
            animation-delay: .5s;
        }
        .dot-flashing::before, .dot-flashing::after {
            content: '';
            display: inline-block;
            position: absolute;
            top: 0;
        }
        .dot-flashing::before {
            left: -15px;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #4b5563;
            color: #4b5563;
            animation: dotFlashing 1s infinite alternate;
            animation-delay: 0s;
        }
        .dot-flashing::after {
            left: 15px;
            width: 10px;
            height: 10px;
            border-radius: 5px;
            background-color: #4b5563;
            color: #4b5563;
            animation: dotFlashing 1s infinite alternate;
            animation-delay: 1s;
        }
        @keyframes dotFlashing {
            0% {
                background-color: #4b5563;
            }
            50%, 100% {
                background-color: #e0e0e0;
            }
        }
    </style>
</head>
<body class="bg-gray-100">

    <div class="flex flex-col h-screen max-w-4xl mx-auto bg-white shadow-2xl rounded-lg overflow-hidden">
        <!-- Header -->
        <header class="bg-gradient-to-r from-gray-800 to-gray-900 text-white p-6 shadow-lg">
            <h1 class="text-3xl font-bold text-center">ArchAI</h1>
            <p class="text-center text-gray-300 text-sm">Your AI Architectural Evaluation Assistant</p>
        </header>

        <!-- Chat History -->
        <main id="chat-history" class="flex-1 overflow-y-auto p-6 space-y-6">
            <!-- Initial Welcome Message -->
            <div class="flex group">
                <div class="flex-shrink-0 h-10 w-10 rounded-full bg-gray-800 flex items-center justify-center">
                    <svg class="h-6 w-6 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M8.25 9V5.25A2.25 2.25 0 0 1 10.5 3h6a2.25 2.25 0 0 1 2.25 2.25v13.5A2.25 2.25 0 0 1 16.5 21h-6a2.25 2.25 0 0 1-2.25-2.25V15m-3 0-3-3m0 0 3-3m-3 3H15" />
                    </svg>
                </div>
                <div class="ml-4 p-4 bg-gray-100 rounded-r-lg rounded-bl-lg max-w-lg">
                    <p class="font-semibold text-gray-800">ArchAI</p>
                    <p class="text-gray-700">Welcome! Please describe your house idea. You can also upload a sketch or reference image of your site or inspiration.</p>
                </div>
            </div>
            <!-- Chat messages will be appended here -->
        </main>

        <!-- Loading Indicator -->
        <div id="loading-indicator" class="hidden flex items-center justify-center p-4">
            <div class="dot-flashing"></div>
            <span id="loading-text" class="ml-4 text-gray-600 font-medium">ArchAI is thinking...</span>
        </div>

        <!-- Input Area -->
        <footer class="bg-gray-50 border-t border-gray-200 p-4">
            <div class="flex items-start space-x-3">
                <!-- File Input -->
                <label for="file-upload" class="cursor-pointer p-3 rounded-full text-gray-600 bg-gray-200 hover:bg-gray-300 transition-colors">
                    <svg class="h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" d="m2.25 15.75 5.159-5.159a2.25 2.25 0 0 1 3.182 0l5.159 5.159m-1.5-1.5 1.409-1.409a2.25 2.25 0 0 1 3.182 0l2.909 2.909m-18 3.75h16.5a1.5 1.5 0 0 0 1.5-1.5V6a1.5 1.5 0 0 0-1.5-1.5H3.75A1.5 1.5 0 0 0 2.25 6v12a1.5 1.5 0 0 0 1.5 1.5Zm16.5-1.5H3.75V6H20.25v12Z" />
                    </svg>
                    <input id="file-upload" type="file" class="hidden" accept="image/*" onchange="handleFileSelect(event)">
                </label>

                <!-- Text Input -->
                <textarea id="chat-input" class="flex-1 border border-gray-300 rounded-lg p-3 resize-none focus:outline-none focus:ring-2 focus:ring-gray-800" placeholder="e.g., A 3-bedroom house for a cold, snowy climate..." rows="1" oninput="autoExpand(this)" onkeydown="handleEnter(event)"></textarea>
                
                <!-- Send Button -->
                <button id="send-button" onclick="sendMessage()" class="bg-gray-800 text-white font-semibold px-5 py-3 rounded-lg hover:bg-gray-700 transition-colors disabled:opacity-50 disabled:cursor-not-allowed">
                    Send
                </button>
            </div>
            <!-- File Preview -->
            <div id="file-preview-container" class="hidden items-center mt-3 ml-16">
                <img id="file-preview" class="h-12 w-12 rounded-md object-cover">
                <span id="file-name" class="ml-3 text-sm text-gray-600"></span>
                <button onclick="removeFile()" class="ml-2 text-gray-500 hover:text-red-500">&times;</button>
            </div>
        </footer>
    </div>

    <script>
        // === State Variables ===
        const chatHistory = document.getElementById('chat-history');
        const chatInput = document.getElementById('chat-input');
        const sendButton = document.getElementById('send-button');
        const loadingIndicator = document.getElementById('loading-indicator');
        const loadingText = document.getElementById('loading-text');
        
        const fileUpload = document.getElementById('file-upload');
        const filePreviewContainer = document.getElementById('file-preview-container');
        const filePreview = document.getElementById('file-preview');
        const fileName = document.getElementById('file-name');

        let uploadedFileB64 = null;
        let uploadedFileType = null;

        // === API Configuration ===
        // IMPORTANT: Leave apiKey as "" - it will be handled by the environment.
        const apiKey = ""; 
        const geminiApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;
        const imagenApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${apiKey}`;

        // === Event Handlers ===

        // Handle file selection
        function handleFileSelect(event) {
            const file = event.target.files[0];
            if (file) {
                fileName.textContent = file.name;
                uploadedFileType = file.type;

                const reader = new FileReader();
                reader.onload = (e) => {
                    filePreview.src = e.target.result;
                    uploadedFileB64 = e.target.result.split(',')[1]; // Get base64 data
                    filePreviewContainer.classList.remove('hidden');
                    filePreviewContainer.classList.add('flex');
                };
                reader.readAsDataURL(file);
            }
        }

        // Remove the selected file
        function removeFile() {
            uploadedFileB64 = null;
            uploadedFileType = null;
            fileUpload.value = null; // Clear the input
            filePreviewContainer.classList.add('hidden');
            filePreviewContainer.classList.remove('flex');
        }

        // Auto-expand text area
        function autoExpand(field) {
            field.style.height = 'inherit';
            const computed = window.getComputedStyle(field);
            const height = parseInt(computed.getPropertyValue('border-top-width'), 10)
                         + parseInt(computed.getPropertyValue('padding-top'), 10)
                         + field.scrollHeight
                         + parseInt(computed.getPropertyValue('padding-bottom'), 10)
                         + parseInt(computed.getPropertyValue('border-bottom-width'), 10);
            field.style.height = height + 'px';
            if (height > 200) {
                field.style.overflowY = 'auto';
            } else {
                field.style.overflowY = 'hidden';
            }
        }
        
        // Send message on Enter key, Shift+Enter for new line
        function handleEnter(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendMessage();
            }
        }

        // === Main Send Function ===
        async function sendMessage() {
            const prompt = chatInput.value.trim();
            if (prompt === "" && !uploadedFileB64) {
                return; // Don't send empty messages
            }

            // 1. Display User Message
            displayUserMessage(prompt, uploadedFileB64 ? filePreview.src : null);

            // 2. Clear inputs and show loading
            chatInput.value = "";
            autoExpand(chatInput);
            removeFile();
            setLoading(true, "ArchAI is thinking...");

            // 3. --- Call Gemini for Analysis ---
            try {
                const geminiPayload = buildGeminiPayload(prompt);
                const geminiResponse = await callApiWithBackoff(geminiApiUrl, geminiPayload);
                const analysisText = geminiResponse.candidates[0].content.parts[0].text;

                // 4. Display Bot Analysis
                displayBotMessage(analysisText, "ArchAI");

                // 5. --- Extract Image Prompt and Call Imagen ---
                const imagePrompt = extractImagePrompt(analysisText);
                if (imagePrompt) {
                    setLoading(true, "Generating conceptual image...");
                    const imagenPayload = {
                        instances: [{ prompt: imagePrompt }],
                        parameters: { "sampleCount": 1 }
                    };
                    
                    const imagenResponse = await callApiWithBackoff(imagenApiUrl, imagenPayload);
                    const imageB64 = imagenResponse.predictions[0].bytesBase64Encoded;
                    
                    // 6. Display Generated Image
                    displayGeneratedImage(imageB64, imagePrompt);

                } else {
                    console.log("No image prompt found in analysis text.");
                }

            } catch (error) {
                console.error("API Error:", error);
                displayBotMessage(`Sorry, I encountered an error: ${error.message}`, "ArchAI", true);
            } finally {
                setLoading(false);
            }
        }

        // === API Call Functions ===

        /**
         * Builds the payload for the Gemini 2.5 Flash API call.
         */
        function buildGeminiPayload(prompt) {
            const systemPrompt = `You are ArchAI, a helpful and creative architectural evaluation assistant.
Your task is to analyze the user's request (text and/or image) and provide a detailed architectural concept.
You MUST follow these steps:
1.  **Analyze Request:** Identify the core needs (e.g., house size, style, environment, problem to solve).
2.  **Environmental Context:** State the primary environmental factors (e.g., "hot-desert", "cold-snowy", "temperate-urban").
3.  **Merge Principles:** Propose a design that merges one modern architectural principle and one ancient or vernacular principle suited for that environment. (e.g., "Modern: High-performance triple-glazed windows. Ancient: Thick, high-thermal-mass walls like adobe or rammed earth.")
4.  **Benefits & Problem-Solving:** Clearly explain *how* this hybrid design solves the environmental challenges (e.g., "The thick walls absorb heat during the day and release it at night, while the windows prevent heat loss...").
5.  **Conceptual Materials:** List 3-5 key *conceptual* materials for this design (e.g., "Rammed Earth", "Recycled Steel Beams", "Green Roof System").
6.  **Conceptual Structure Note:** Add a *brief, conceptual* note on the structure. **DO NOT provide structural calculations, load-bearing capacities, or any engineering specifications.** (e.g., "The structure could be a hybrid of load-bearing earth walls and a steel frame to support large roof spans.")
7.  **Image Prompt:** After all other text, add a special line:
    PROMPT_FOR_IMAGE: [A 10-15 word, visually descriptive prompt for an image generator. Example: "An exterior architectural rendering of a modern-ancient hybrid house in a desert, featuring rammed earth walls and large glass windows, cinematic lighting."]
`;
            const payload = {
                contents: [{
                    parts: []
                }],
                systemInstruction: {
                    parts: [{ text: systemPrompt }]
                },
            };

            // Add text part
            if (prompt) {
                payload.contents[0].parts.push({ text: `User's Idea: ${prompt}` });
            } else {
                payload.contents[0].parts.push({ text: "The user did not provide text, please analyze the image." });
            }

            // Add image part
            if (uploadedFileB64 && uploadedFileType) {
                payload.contents[0].parts.push({
                    inlineData: {
                        mimeType: uploadedFileType,
                        data: uploadedFileB64
                    }
                });
            }
            
            return payload;
        }

        /**
         * Extracts the dedicated image prompt from the bot's text response.
         */
        function extractImagePrompt(text) {
            const match = text.match(/PROMPT_FOR_IMAGE:\s*\[(.*?)\]/);
            if (match && match[1]) {
                return match[1];
            }
            // Fallback if the model failed to format
            return `An exterior architectural rendering of ${chatInput.value.trim()}`;
        }

        /**
         * Calls an API with exponential backoff for retries.
         */
        async function callApiWithBackoff(url, payload, retries = 3, delay = 1000) {
            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status} ${response.statusText}`);
                }
                
                const result = await response.json();

                // Check for API-specific errors in the response body
                if (result.error) {
                    throw new Error(result.error.message);
                }
                if (!result.candidates && !result.predictions) {
                    throw new Error("Invalid API response structure.");
                }

                return result;

            } catch (error) {
                if (retries > 0) {
                    // Don't log to console, just wait and retry
                    await new Promise(res => setTimeout(res, delay));
                    return callApiWithBackoff(url, payload, retries - 1, delay * 2);
                } else {
                    // All retries failed, throw the last error
                    throw error;
                }
            }
        }


        // === UI Display Functions ===

        /**
         * Sets the loading state.
         */
        function setLoading(isLoading, text = "ArchAI is thinking...") {
            if (isLoading) {
                loadingIndicator.classList.remove('hidden');
                loadingIndicator.classList.add('flex');
                loadingText.textContent = text;
                sendButton.disabled = true;
            } else {
                loadingIndicator.classList.add('hidden');
                loadingIndicator.classList.remove('flex');
                sendButton.disabled = false;
            }
        }

        /**
         * Displays a message from the user.
         */
        function displayUserMessage(text, imgSrc) {
            let messageHtml = `
                <div class="flex justify-end group">
                    <div class="mr-4 p-4 bg-gray-800 text-white rounded-l-lg rounded-br-lg max-w-lg">
                        <p class="font-semibold">You</p>
                        <p>${text.replace(/\n/g, '<br>')}</p>
            `;
            
            if (imgSrc) {
                messageHtml += `<img src="${imgSrc}" class="mt-3 rounded-lg max-w-xs" alt="User upload">`;
            }

            messageHtml += `
                    </div>
                    <div class="flex-shrink-0 h-10 w-10 rounded-full bg-gray-200 flex items-center justify-center">
                        <svg class="h-6 w-6 text-gray-600" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M15.75 6a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0ZM4.501 20.118a7.5 7.5 0 0 1 14.998 0A1.5 1.5 0 0 1 18 21.75H6a1.5 1.5 0 0 1-1.499-1.632Z" />
                        </svg>
                    </div>
                </div>
            `;
            chatHistory.innerHTML += messageHtml;
            scrollToBottom();
        }

        /**
         * Displays a message from the bot.
         */
        function displayBotMessage(text, sender, isError = false) {
            // Sanitize and format the text.
            // Replace PROMPT_FOR_IMAGE line
            let formattedText = text.replace(/PROMPT_FOR_IMAGE:.*$/m, ""); 
            // Basic markdown for bolding (e.g., **Text**) and lists
            formattedText = formattedText.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            formattedText = formattedText.replace(/^\* (.*$)/gm, '<li class="ml-4 list-disc">$1</li>');
            formattedText = formattedText.replace(/\n/g, '<br>');

            const bgColor = isError ? 'bg-red-100' : 'bg-gray-100';
            const textColor = isError ? 'text-red-800' : 'text-gray-700';
            const senderColor = isError ? 'text-red-900' : 'text-gray-800';

            const messageHtml = `
                <div class="flex group">
                    <div class="flex-shrink-0 h-10 w-10 rounded-full bg-gray-800 flex items-center justify-center">
                         <svg class="h-6 w-6 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M8.25 9V5.25A2.25 2.25 0 0 1 10.5 3h6a2.25 2.25 0 0 1 2.25 2.25v13.5A2.25 2.25 0 0 1 16.5 21h-6a2.25 2.25 0 0 1-2.25-2.25V15m-3 0-3-3m0 0 3-3m-3 3H15" />
                        </svg>
                    </div>
                    <div class="ml-4 p-4 ${bgColor} rounded-r-lg rounded-bl-lg max-w-lg">
                        <p class="font-semibold ${senderColor}">${sender}</p>
                        <div class="prose prose-sm max-w-none ${textColor}">${formattedText}</div>
                    </div>
                </div>
            `;
            chatHistory.innerHTML += messageHtml;
            scrollToBottom();
        }
        
        /**
         * Displays the generated image from Imagen.
         */
        function displayGeneratedImage(base64Data, altText) {
             const messageHtml = `
                <div class="flex group">
                    <div class="flex-shrink-0 h-10 w-10 rounded-full bg-gray-800 flex items-center justify-center">
                         <svg class="h-6 w-6 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M8.25 9V5.25A2.25 2.25 0 0 1 10.5 3h6a2.25 2.25 0 0 1 2.25 2.25v13.5A2.25 2.25 0 0 1 16.5 21h-6a2.25 2.25 0 0 1-2.25-2.25V15m-3 0-3-3m0 0 3-3m-3 3H15" />
                        </svg>
                    </div>
                    <div class="ml-4 p-4 bg-gray-100 rounded-r-lg rounded-bl-lg max-w-lg">
                        <p class="font-semibold text-gray-800">ArchAI (Conceptual Image)</p>
                        <img src="data:image/png;base64,${base64Data}" class="mt-2 rounded-lg" alt="Generated architectural concept: ${altText}">
                    </div>
                </div>
            `;
            chatHistory.innerHTML += messageHtml;
            scrollToBottom();
        }

        /**
         * Scrolls the chat history to the bottom.
         */
        function scrollToBottom() {
            chatHistory.scrollTop = chatHistory.scrollHeight;

        }

        // Initial focus on input
        chatInput.focus();
    </script>
</body>
</html>